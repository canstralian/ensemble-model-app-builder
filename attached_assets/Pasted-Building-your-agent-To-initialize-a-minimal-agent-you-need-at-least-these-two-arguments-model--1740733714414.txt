Building your agent
To initialize a minimal agent, you need at least these two arguments:

model, a text-generation model to power your agent - because the agent is different from a simple LLM, it is a system that uses a LLM as its engine. You can use any of these options:

TransformersModel takes a pre-initialized transformers pipeline to run inference on your local machine using transformers.
HfApiModel leverages a huggingface_hub.InferenceClient under the hood and supports all Inference Providers on the Hub.
LiteLLMModel similarly lets you call 100+ different models and providers through LiteLLM!
AzureOpenAIServerModel allows you to use OpenAI models deployed in Azure.
MLXModel creates a mlx-lm pipeline to run inference on your local machine.
tools, a list of Tools that the agent can use to solve the task. It can be an empty list. You can also add the default toolbox on top of your tools list by defining the optional argument add_base_tools=True.

Once you have these two arguments, tools and model, you can create an agent and run it. You can use any LLM you’d like, either through Inference Providers, transformers, ollama, LiteLLM, Azure OpenAI, or mlx-lm.

HF Inference API is free to use without a token, but then it will have a rate limit.

To access gated models or rise your rate limits with a PRO account, you need to set the environment variable HF_TOKEN or pass token variable upon initialization of HfApiModel. You can get your token from your settings page

Copied
from smolagents import CodeAgent, HfApiModel

model_id = "meta-llama/Llama-3.3-70B-Instruct" 

model = HfApiModel(model_id=model_id, token="<YOUR_HUGGINGFACEHUB_API_TOKEN>") # You can choose to not pass any model_id to HfApiModel to use a default free model
# you can also specify a particular provider e.g. provider="together" or provider="sambanova"
agent = CodeAgent(tools=[], model=model, add_base_tools=True)

agent.run(
    "Could you give me the 118th number in the Fibonacci sequence?",
)
CodeAgent and ToolCallingAgent
The CodeAgent is our default agent. It will write and execute python code snippets at each step.

By default, the execution is done in your local environment. This should be safe because the only functions that can be called are the tools you provided (especially if it’s only tools by Hugging Face) and a set of predefined safe functions like print or functions from the math module, so you’re already limited in what can be executed.

The Python interpreter also doesn’t allow imports by default outside of a safe list, so all the most obvious attacks shouldn’t be an issue. You can authorize additional imports by passing the authorized modules as a list of strings in argument additional_authorized_imports upon initialization of your CodeAgent:

Copied
model = HfApiModel()
agent = CodeAgent(tools=[], model=model, additional_authorized_imports=['requests', 'bs4'])
agent.run("Could you get me the title of the page at url 'https://huggingface.co/blog'?")